{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ray7788/FT5005-Group6/blob/main/Cleaned%20Data/EBITDA_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CSNOUqVWDN3G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSNOUqVWDN3G",
        "outputId": "55ee90a4-ba07-4404-f0dd-b6d8b0b9cb31"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab\\ Notebooks/FT5005/Cleaned\\ Data/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7676818c",
      "metadata": {
        "id": "7676818c"
      },
      "source": [
        "Data Cleaning for **Revenue**\n",
        "========================\n",
        "This notebook contains the data cleaning process for the revenue dataset used in the project.\n",
        "\n",
        "The input dataset is a CSV file which is merged and preprocessed from the FT5005 professor's official dataset and self-explored dataset. The file used for this process is `revenue_preprocess.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8cfddd36",
      "metadata": {
        "id": "8cfddd36"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bed28a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "bed28a4f",
        "outputId": "dad8245c-03fb-45c6-9cdc-30199c30c88d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['tic', 'datafqtr', 'cshoq', 'cshtrq', 'capxy', 'oiadpq', 'niq', 'xoprq', 'teqq', 'atq', 'epsfiq', 'cshoq.1', 'cshtrq.1', 'capxy.1', 'oiadpq.1', 'niq.1', 'xoprq.1', 'teqq.1', 'atq.1', 'epsfiq.1', 'gmrmexpq', 'gmrmrevq', 'hbinvfhq', 'hbinvludq', 'hbinvtq', 'hbloq', 'conm', 'revtq', 'sentiment_x', 'sentiment_y', 'SALE PRICE', 'Real GDP SA(billion)', 'M2 SA(billion)', 'M2-M1 Growth Gap(%)', 'M2V', 'Prime Rate(%)']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tic</th>\n",
              "      <th>datafqtr</th>\n",
              "      <th>cshoq</th>\n",
              "      <th>cshtrq</th>\n",
              "      <th>capxy</th>\n",
              "      <th>oiadpq</th>\n",
              "      <th>niq</th>\n",
              "      <th>xoprq</th>\n",
              "      <th>teqq</th>\n",
              "      <th>atq</th>\n",
              "      <th>...</th>\n",
              "      <th>conm</th>\n",
              "      <th>revtq</th>\n",
              "      <th>sentiment_x</th>\n",
              "      <th>sentiment_y</th>\n",
              "      <th>SALE PRICE</th>\n",
              "      <th>Real GDP SA(billion)</th>\n",
              "      <th>M2 SA(billion)</th>\n",
              "      <th>M2-M1 Growth Gap(%)</th>\n",
              "      <th>M2V</th>\n",
              "      <th>Prime Rate(%)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NLP</td>\n",
              "      <td>2010Q1</td>\n",
              "      <td>10.666</td>\n",
              "      <td>-2.568</td>\n",
              "      <td>10.666</td>\n",
              "      <td>11.450</td>\n",
              "      <td>263614.0</td>\n",
              "      <td>11.450</td>\n",
              "      <td>263614.0</td>\n",
              "      <td>63.433</td>\n",
              "      <td>...</td>\n",
              "      <td>263614.0</td>\n",
              "      <td>63.433</td>\n",
              "      <td>0.0</td>\n",
              "      <td>63.433</td>\n",
              "      <td>0.0</td>\n",
              "      <td>309.571</td>\n",
              "      <td>0.209</td>\n",
              "      <td>309.571</td>\n",
              "      <td>0.209</td>\n",
              "      <td>-0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NLP</td>\n",
              "      <td>2010Q2</td>\n",
              "      <td>10.666</td>\n",
              "      <td>-2.608</td>\n",
              "      <td>10.666</td>\n",
              "      <td>12.143</td>\n",
              "      <td>235341.0</td>\n",
              "      <td>12.143</td>\n",
              "      <td>235341.0</td>\n",
              "      <td>59.999</td>\n",
              "      <td>...</td>\n",
              "      <td>235341.0</td>\n",
              "      <td>59.999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.999</td>\n",
              "      <td>0.0</td>\n",
              "      <td>304.493</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>304.493</td>\n",
              "      <td>-0.307</td>\n",
              "      <td>-0.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NLP</td>\n",
              "      <td>2010Q3</td>\n",
              "      <td>10.666</td>\n",
              "      <td>-3.197</td>\n",
              "      <td>10.666</td>\n",
              "      <td>11.950</td>\n",
              "      <td>159175.0</td>\n",
              "      <td>11.950</td>\n",
              "      <td>159175.0</td>\n",
              "      <td>55.925</td>\n",
              "      <td>...</td>\n",
              "      <td>159175.0</td>\n",
              "      <td>55.925</td>\n",
              "      <td>0.0</td>\n",
              "      <td>55.925</td>\n",
              "      <td>0.0</td>\n",
              "      <td>299.536</td>\n",
              "      <td>0.336</td>\n",
              "      <td>299.536</td>\n",
              "      <td>0.336</td>\n",
              "      <td>-0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NLP</td>\n",
              "      <td>2010Q4</td>\n",
              "      <td>10.666</td>\n",
              "      <td>-3.023</td>\n",
              "      <td>10.666</td>\n",
              "      <td>11.716</td>\n",
              "      <td>163338.0</td>\n",
              "      <td>11.716</td>\n",
              "      <td>163338.0</td>\n",
              "      <td>52.167</td>\n",
              "      <td>...</td>\n",
              "      <td>163338.0</td>\n",
              "      <td>52.167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52.167</td>\n",
              "      <td>0.0</td>\n",
              "      <td>328.566</td>\n",
              "      <td>0.642</td>\n",
              "      <td>328.566</td>\n",
              "      <td>0.642</td>\n",
              "      <td>-0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NLP</td>\n",
              "      <td>2011Q1</td>\n",
              "      <td>10.666</td>\n",
              "      <td>-3.392</td>\n",
              "      <td>10.666</td>\n",
              "      <td>12.967</td>\n",
              "      <td>177414.0</td>\n",
              "      <td>12.967</td>\n",
              "      <td>177414.0</td>\n",
              "      <td>48.098</td>\n",
              "      <td>...</td>\n",
              "      <td>177414.0</td>\n",
              "      <td>48.098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>48.098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>325.605</td>\n",
              "      <td>0.476</td>\n",
              "      <td>325.605</td>\n",
              "      <td>0.476</td>\n",
              "      <td>-0.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   tic datafqtr   cshoq  cshtrq   capxy  oiadpq       niq   xoprq      teqq  \\\n",
              "0  NLP   2010Q1  10.666  -2.568  10.666  11.450  263614.0  11.450  263614.0   \n",
              "1  NLP   2010Q2  10.666  -2.608  10.666  12.143  235341.0  12.143  235341.0   \n",
              "2  NLP   2010Q3  10.666  -3.197  10.666  11.950  159175.0  11.950  159175.0   \n",
              "3  NLP   2010Q4  10.666  -3.023  10.666  11.716  163338.0  11.716  163338.0   \n",
              "4  NLP   2011Q1  10.666  -3.392  10.666  12.967  177414.0  12.967  177414.0   \n",
              "\n",
              "      atq  ...      conm   revtq  sentiment_x  sentiment_y  SALE PRICE  \\\n",
              "0  63.433  ...  263614.0  63.433          0.0       63.433         0.0   \n",
              "1  59.999  ...  235341.0  59.999          0.0       59.999         0.0   \n",
              "2  55.925  ...  159175.0  55.925          0.0       55.925         0.0   \n",
              "3  52.167  ...  163338.0  52.167          0.0       52.167         0.0   \n",
              "4  48.098  ...  177414.0  48.098          0.0       48.098         0.0   \n",
              "\n",
              "   Real GDP SA(billion)  M2 SA(billion)  M2-M1 Growth Gap(%)    M2V  \\\n",
              "0               309.571           0.209              309.571  0.209   \n",
              "1               304.493          -0.307              304.493 -0.307   \n",
              "2               299.536           0.336              299.536  0.336   \n",
              "3               328.566           0.642              328.566  0.642   \n",
              "4               325.605           0.476              325.605  0.476   \n",
              "\n",
              "   Prime Rate(%)  \n",
              "0          -0.23  \n",
              "1          -0.23  \n",
              "2          -0.28  \n",
              "3          -0.26  \n",
              "4          -0.30  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"revenue_preprocess.csv\")\n",
        "print(df.columns.tolist())\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "641d9a0d",
      "metadata": {
        "id": "641d9a0d"
      },
      "source": [
        "# Rename columns for better readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a4c52ac7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4c52ac7",
        "outputId": "97a031c2-7ea8-4a26-f3d3-1ada3b6d2ecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ticker', 'fiscalQuarter', 'commonSharesOutstanding_', 'commonSharesTraded_', 'capitalExpenditure_', 'operatingIncome_', 'netIncome_', 'operatingIncome_', 'shareholdersEquity_', 'totalAssets_', 'EPS_', 'companyName', 'revenue_', 'salePrice', 'realGDPSA', 'm2SA', 'm2m1GrowthGap', 'm2Velocity', 'primeRate']\n"
          ]
        }
      ],
      "source": [
        "# Rename DataFrame columns to follow camelCase convention and match original definitions from the images\n",
        "\n",
        "# Basic company identifiers\n",
        "df = df.rename(columns={\n",
        "    'tic': 'ticker',  # Stock ticker symbol\n",
        "    'datafqtr': 'fiscalQuarter',  # Fiscal quarter date\n",
        "    'conm': 'companyName'  # Company name\n",
        "})\n",
        "\n",
        "# Target variables (what we're trying to predict)\n",
        "df = df.rename(columns={\n",
        "    # Mean sale price per quarter (from additional variables)\n",
        "    'SALE PRICE': 'salePrice'\n",
        "})\n",
        "\n",
        "# Basic financial variables (raw data from financial statements)\n",
        "df = df.rename(columns={\n",
        "    'cshoq': 'commonSharesOutstanding_',  # Number of common shares outstanding\n",
        "    'cshtrq': 'commonSharesTraded_',  # Common shares traded\n",
        "    'capxy': 'capitalExpenditure_',  # Funds used to acquire/upgrade physical assets\n",
        "\n",
        "    'oiadpq': 'operatingIncome_',  # Operating income before depreciation\n",
        "    'revtq': 'revenue_',  # Total revenue (sales) for the quarter\n",
        "\n",
        "    'niq': 'netIncome_',  # Net income (profit after all expenses)\n",
        "    'xoprq': 'operatingIncome_',  # Operating income after depreciation\n",
        "    'teqq': 'shareholdersEquity_',  # Total shareholders' equity\n",
        "    'atq': 'totalAssets_',  # Total assets on balance sheet\n",
        "    'epsfiq': 'EPS_',  # Earnings per share (profit per outstanding share)\n",
        "    'cogsq': 'costOfGoodsSold_'  # Cost of goods sold\n",
        "})\n",
        "\n",
        "# Engineered financial features (calculated metrics)\n",
        "df = df.rename(columns={\n",
        "    'Debt_to_TA': 'debtToTotalAssets',  # Total debt divided by total assets\n",
        "    'NI_to_Asset': 'niToAsset',  # Net income divided by average assets\n",
        "    'ROA': 'ROA',  # Return on assets (net income/total assets)\n",
        "    'ROE': 'ROE',  # Return on equity (net income/shareholders' equity)\n",
        "    'Revenue_growth': 'revenueGrowth',  # Quarter-over-quarter revenue growth\n",
        "    'NI_growth': 'netIncomeGrowth',  # Quarter-over-quarter net income growth\n",
        "    # Current ratio (current assets/current liabilities)\n",
        "    'Current_ratio': 'currentRatio',\n",
        "    # (Current assets - inventories)/current liabilities\n",
        "    'Quick_ratio': 'quickRatio',\n",
        "    'RSI': 'rsi',  # Relative Strength Index (momentum indicator)\n",
        "    'MVA': 'mva',  # Market Value Added (not explicitly defined in images)\n",
        "    'CFROI': 'cfroi',  # Cash flow return on investment (OCF/Capital Employed)\n",
        "\n",
        "})\n",
        "\n",
        "# df = df.rename(columns={\n",
        "#     'gmrmexpq': 'roomsExpensesQuarterly',  # Rooms Expenses Quarterly\n",
        "#     'gmrmrevq': 'roomRevenueQuarterly',  # Room Revenue Quarterly\n",
        "#     'hbinvfhq': 'finishedHomesConstrInProgress',  # Finished Homes/Constr in Progress\n",
        "#     'hbinvludq': 'landUnderDevelopment',  # Land Under Development\n",
        "#     'hbinvtq': 'totalHomebuildingInventories',  # Total Homebuilding Inventories\n",
        "#     'hbloq': 'homesitesLotsOwned'  # Homesites/Lots Owned\n",
        "# })\n",
        "\n",
        "# Macroeconomic variables (external factors)\n",
        "df = df.rename(columns={\n",
        "    'Real GDP SA(billion)': 'realGDPSA',  # Seasonally adjusted real GDP\n",
        "    'M2 SA(billion)': 'm2SA',  # Seasonally adjusted M2 money supply\n",
        "    # Difference between M2 and M1 money supply\n",
        "    'M2-M1 SA(billion)': 'm2MinusM1SA',\n",
        "    # Gap between M2 and M1 growth rates\n",
        "    'M2-M1 Growth Gap(%)': 'm2m1GrowthGap',\n",
        "    'M2V': 'm2Velocity',  # Velocity of M2 money supply\n",
        "    'Prime Rate(%)': 'primeRate'  # Benchmark interest rate\n",
        "})\n",
        "\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['cshoq.1', 'cshtrq.1', 'capxy.1', 'oiadpq.1', 'niq.1', 'xoprq.1', 'teqq.1', 'atq.1', 'epsfiq.1',\n",
        "                      'gmrmexpq',\n",
        "                      'gmrmrevq',\n",
        "                      'hbinvfhq',\n",
        "                      'hbinvludq',\n",
        "                      'hbinvtq',\n",
        "                      'hbloq',\n",
        "                      'sentiment_x',\n",
        "                      'sentiment_y',\n",
        "                      #   'm2m1GrowthGap',\n",
        "                      #   'm2Velocity'\n",
        "                      ])\n",
        "\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "170dbb28",
      "metadata": {
        "id": "170dbb28"
      },
      "source": [
        "# Company selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "58b7460b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58b7460b",
        "outputId": "e7aa3b72-eaa4-422d-a7db-ef4e4ba585fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEN is in the DataFrame\n",
            "LEJUY is in the DataFrame\n",
            "MRCBF is in the DataFrame\n",
            "ACAN is in the DataFrame\n",
            "MDPCF is in the DataFrame\n",
            "HMT. is in the DataFrame\n",
            "GYRO is in the DataFrame\n",
            "PRLEQ is in the DataFrame\n",
            "MYCB is in the DataFrame\n",
            "TNL is in the DataFrame\n",
            "MODVF is in the DataFrame\n",
            "ARL is in the DataFrame\n"
          ]
        }
      ],
      "source": [
        "nyc_real_estate_tickers = [\n",
        "    'NEN',  # New York Mortgage Trust, Inc.\n",
        "    'LEJUY',  # Leju Holdings Limited\n",
        "    'MRCBF',   # Cushman & Wakefield plc\n",
        "    'ACAN',  # Douglas Elliman Inc.\n",
        "    'MDPCF',   # Jones Lang LaSalle Inc.\n",
        "    'HMT.',  # Anywhere Real Estate Inc.\n",
        "    'GYRO',  # RE/MAX Holdings, Inc.\n",
        "    'PRLEQ',  # eXp World Holdings, Inc.\n",
        "    'MYCB',  # Opendoor Technologies Inc.\n",
        "    'TNL',  # Offerpad Solutions Inc.\n",
        "    'MODVF',  # KE Holdings Inc. (Limited NYC presence)\n",
        "    'ARL',  # Redfin Corporation\n",
        "]\n",
        "# Check if these tickers are in the DataFrame, which are not in the original list\n",
        "for ticker in nyc_real_estate_tickers:\n",
        "    if ticker not in df['ticker'].values:\n",
        "        print(f\"{ticker} is not in the DataFrame\")\n",
        "    else:\n",
        "        print(f\"{ticker} is in the DataFrame\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0a14d1bc",
      "metadata": {
        "id": "0a14d1bc"
      },
      "outputs": [],
      "source": [
        "selected_companies = df[df['ticker'].isin(nyc_real_estate_tickers)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c9f855",
      "metadata": {
        "id": "78c9f855"
      },
      "source": [
        "# Process before the data cleaning phase\n",
        "## Remove unnecessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "62ed7fdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ed7fdb",
        "outputId": "eca5786c-7670-4fca-b6fb-9f2d77a851f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No duplicate rows in selected companies DataFrame\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicate rows in the selected companies DataFrame\n",
        "duplicate_rows = selected_companies[selected_companies.duplicated()]\n",
        "if not duplicate_rows.empty:\n",
        "    print(\"Duplicate rows in selected companies DataFrame:\")\n",
        "    print(duplicate_rows)\n",
        "else:\n",
        "    print(\"No duplicate rows in selected companies DataFrame\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d623ba2",
      "metadata": {
        "id": "3d623ba2"
      },
      "source": [
        "## Check missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "06893d24",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06893d24",
        "outputId": "70605e6c-2abc-4d88-bda2-2ba3705e36e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numeric columns in selected companies DataFrame:\n",
            "['commonSharesOutstanding_', 'commonSharesTraded_', 'capitalExpenditure_', 'operatingIncome_', 'netIncome_', 'operatingIncome_', 'shareholdersEquity_', 'totalAssets_', 'EPS_', 'companyName', 'revenue_', 'salePrice', 'realGDPSA', 'm2SA', 'm2m1GrowthGap', 'm2Velocity', 'primeRate']\n",
            "Missing values in numeric columns of selected companies DataFrame:\n",
            "netIncome_             6\n",
            "shareholdersEquity_    6\n",
            "companyName            6\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check numeric columns from the selected companies DataFrame\n",
        "numeric_columns = selected_companies.select_dtypes(include=[np.number]).columns.tolist()\n",
        "print(\"Numeric columns in selected companies DataFrame:\")\n",
        "print(numeric_columns)\n",
        "# Check for missing values in the numeric columns\n",
        "missing_numeric_values = selected_companies[numeric_columns].isnull().sum()\n",
        "missing_numeric_values = missing_numeric_values[missing_numeric_values > 0]\n",
        "if not missing_numeric_values.empty:\n",
        "    print(\"Missing values in numeric columns of selected companies DataFrame:\")\n",
        "    print(missing_numeric_values)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25480435",
      "metadata": {
        "id": "25480435"
      },
      "source": [
        "# Preprocessing Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "052fb653",
      "metadata": {
        "id": "052fb653"
      },
      "source": [
        "## Numerical features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cfa5bb7",
      "metadata": {
        "id": "0cfa5bb7"
      },
      "source": [
        "### Process Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "355f1b6e",
      "metadata": {
        "id": "355f1b6e"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "def handle_outliers(df, columns):\n",
        "    \"\"\"\n",
        "    Handle outliers using the IQR method, clipping data to a reasonable range.\n",
        "    \"\"\"\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df[col] = df[col].clip(lower_bound, upper_bound)\n",
        "    return df\n",
        "\n",
        "    def handle_outliers_winsorize(df, columns, limits=(0.05, 0.05)):\n",
        "        \"\"\"\n",
        "        Handle outliers using winsorization, which limits extreme values to a specified percentile.\n",
        "        \"\"\"\n",
        "        for col in columns:\n",
        "            df[col] = winsorize(df[col], limits=limits)\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1282402",
      "metadata": {
        "id": "d1282402"
      },
      "source": [
        "### Normalize numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e2d01f19",
      "metadata": {
        "id": "e2d01f19"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "\n",
        "def scale_features(df, columns):\n",
        "    \"\"\"\n",
        "    Standardize numerical features.\n",
        "    \"\"\"\n",
        "    scaler = RobustScaler()\n",
        "    df[columns] = scaler.fit_transform(df[columns])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cb89d0",
      "metadata": {
        "id": "66cb89d0"
      },
      "source": [
        "### Utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0ce61a6e",
      "metadata": {
        "id": "0ce61a6e"
      },
      "outputs": [],
      "source": [
        "def add_time_series_features(df):\n",
        "    \"\"\"\n",
        "    Add time series features, such as lag values and time-related features.\n",
        "    \"\"\"\n",
        "    df = df.sort_values(['ticker', 'fiscalQuarter'])\n",
        "    df['EBITDA_lag1'] = df.groupby('ticker')['EBITDA'].shift(1)\n",
        "    df['year'] = df['fiscalQuarter'].str[:4].astype(int)\n",
        "    df['quarter'] = df['fiscalQuarter'].str[-1].astype(int)\n",
        "    return df\n",
        "\n",
        "\n",
        "def remove_multicollinearity(df, columns_to_drop):\n",
        "    \"\"\"\n",
        "    Remove columns with high multicollinearity. Supports dropping multiple columns.\n",
        "    \"\"\"\n",
        "    if isinstance(columns_to_drop, list):\n",
        "        df = df.drop(columns=columns_to_drop)\n",
        "    else:\n",
        "        raise ValueError(\"columns_to_drop should be a list of column names.\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0b1e3c5",
      "metadata": {
        "id": "e0b1e3c5"
      },
      "source": [
        "### Process missing (Null) values\n",
        "<!--\n",
        "EPS_                         9\n",
        "commonSharesOutstanding_    24\n",
        "commonSharesTraded_         54\n",
        "quickRatio                  10\n",
        "rsi                         64\n",
        "mva                         70\n",
        "cfroi                       10 -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3d5f05e9",
      "metadata": {
        "id": "3d5f05e9"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in the DataFrame\n",
        "# missing_values = selected_companies.isnull().sum()\n",
        "# # Drop columns with missing values\n",
        "# selected_companies = selected_companies.drop(columns=missing_values[missing_values > 0].index.tolist())\n",
        "def process_missing_value(df, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Handle missing values: drop columns with missing ratio above the threshold\n",
        "    and fill remaining missing values with the median.\n",
        "    \"\"\"\n",
        "    missing_ratio = df.isnull().sum() / len(df)\n",
        "    df = df.drop(columns=missing_ratio[missing_ratio > threshold].index)\n",
        "    for col in df.select_dtypes(include=['float64', 'int64']):\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7fda527e",
      "metadata": {
        "id": "7fda527e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def apply_log_transform(df, columns_to_transform, add_small_constant=True):\n",
        "    \"\"\"\n",
        "    Apply logarithmic transformation to specified columns of a DataFrame (log(1 + x))\n",
        "    to avoid issues with zero or negative values.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Input DataFrame\n",
        "    - columns_to_transform: List of column names to transform\n",
        "    - add_small_constant: Whether to add 1 to the data (to avoid log(0))\n",
        "\n",
        "    Returns:\n",
        "    - Transformed DataFrame\n",
        "    \"\"\"\n",
        "    df_transformed = df.copy()\n",
        "\n",
        "    for col in columns_to_transform:\n",
        "        if col not in df.columns:\n",
        "            print(f\"Warning: Column '{col}' does not exist, skipping\")\n",
        "            continue\n",
        "\n",
        "        if add_small_constant:\n",
        "            # Use log(1 + x) to avoid issues with zero or negative values\n",
        "            df_transformed[col] = np.log1p(df_transformed[col])\n",
        "        else:\n",
        "            # Apply log only to positive values\n",
        "            if (df_transformed[col] <= 0).any():\n",
        "                print(f\"Warning: Column '{col}' contains zero or negative values, consider using log(1 + x) or checking the data\")\n",
        "            df_transformed[col] = np.log(df_transformed[col])\n",
        "\n",
        "    return df_transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b0Ulq_UYDxZB",
      "metadata": {
        "id": "b0Ulq_UYDxZB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode_categorical_features(df, columns):\n",
        "    \"\"\"\n",
        "    Encode categorical features using LabelEncoder.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Input DataFrame\n",
        "    - columns: List of column names to encode\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame with encoded columns\n",
        "    \"\"\"\n",
        "    df_encoded = df.copy()\n",
        "    for col in columns:\n",
        "        encoder = LabelEncoder()\n",
        "        df_encoded[col] = encoder.fit_transform(df_encoded[col])\n",
        "    return df_encoded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "edc82415",
      "metadata": {
        "id": "edc82415"
      },
      "outputs": [],
      "source": [
        "selected_companies.head(3).to_csv(\"selected_companies.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "93094c65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93094c65",
        "outputId": "eb936411-810b-4abb-ce12-7c2dc3d1ba97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/rm/zkx7tx614cq0pcwp0cpgbhy80000gn/T/ipykernel_36636/657722357.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "/var/folders/rm/zkx7tx614cq0pcwp0cpgbhy80000gn/T/ipykernel_36636/657722357.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Must specify axis=0 or 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[31], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Execute preprocessing\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m processed_df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_numeric_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_companies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[31], line 14\u001b[0m, in \u001b[0;36mpreprocess_numeric_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     10\u001b[0m     ratio_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebtToTotalAssets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mniToAsset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPS_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevenueGrowth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetIncomeGrowth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrentRatio\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm2m1GrowthGap\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm2Velocity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimeRate\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m                   ]  \u001b[38;5;66;03m# Exclude ratio columns\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     cols_to_process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(numeric_cols) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(ratio_cols))\n\u001b[0;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols_to_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     df \u001b[38;5;241m=\u001b[39m encode_categorical_features(df, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mticker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompanyName\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# capitalExpenditure_ totalAssets_\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# commonSharesOutstanding_\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[24], line 13\u001b[0m, in \u001b[0;36mhandle_outliers\u001b[0;34m(df, columns)\u001b[0m\n\u001b[1;32m     11\u001b[0m     lower_bound \u001b[38;5;241m=\u001b[39m Q1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR\n\u001b[1;32m     12\u001b[0m     upper_bound \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR\n\u001b[0;32m---> 13\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlower_bound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_bound\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_outliers_winsorize\u001b[39m(df, columns, limits\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.05\u001b[39m)):\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:8749\u001b[0m, in \u001b[0;36mNDFrame.clip\u001b[0;34m(self, lower, upper, axis, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   8747\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   8748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 8749\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clip_with_one_bound\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8750\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\n\u001b[1;32m   8751\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   8752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m upper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:8591\u001b[0m, in \u001b[0;36mNDFrame._clip_with_one_bound\u001b[0;34m(self, threshold, method, axis, inplace)\u001b[0m\n\u001b[1;32m   8588\u001b[0m subset \u001b[38;5;241m=\u001b[39m method(threshold_inf, axis\u001b[38;5;241m=\u001b[39maxis) \u001b[38;5;241m|\u001b[39m isna(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   8590\u001b[0m \u001b[38;5;66;03m# GH 40420\u001b[39;00m\n\u001b[0;32m-> 8591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:10607\u001b[0m, in \u001b[0;36mNDFrame.where\u001b[0;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[1;32m  10601\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10602\u001b[0m                 _chained_assignment_method_msg,\n\u001b[1;32m  10603\u001b[0m                 ChainedAssignmentError,\n\u001b[1;32m  10604\u001b[0m                 stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m  10605\u001b[0m             )\n\u001b[1;32m  10606\u001b[0m other \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mapply_if_callable(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m> 10607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_where\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:10332\u001b[0m, in \u001b[0;36mNDFrame._where\u001b[0;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[1;32m  10328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, NDFrame):\n\u001b[1;32m  10329\u001b[0m     \u001b[38;5;66;03m# align with me\u001b[39;00m\n\u001b[1;32m  10330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m  10331\u001b[0m         \u001b[38;5;66;03m# CoW: Make sure reference is not kept alive\u001b[39;00m\n\u001b[0;32m> 10332\u001b[0m         other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10335\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10336\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10337\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10338\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m  10339\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m  10341\u001b[0m         \u001b[38;5;66;03m# if we are NOT aligned, raise as we cannot where index\u001b[39;00m\n\u001b[1;32m  10342\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_indexed_same(\u001b[38;5;28mself\u001b[39m):\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:10095\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m  10082\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[1;32m  10083\u001b[0m         other,\n\u001b[1;32m  10084\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10091\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10092\u001b[0m     )\n\u001b[1;32m  10094\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m> 10095\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10098\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m  10107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/generic.py:10201\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m  10198\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m  10200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m is_series \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m axis \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m> 10201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify axis=0 or 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_series \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m  10204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot align series to a series other than axis 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Must specify axis=0 or 1"
          ]
        }
      ],
      "source": [
        "def preprocess_numeric_data(df):\n",
        "    \"\"\"\n",
        "    Main function: call sub-functions to preprocess numerical data.\n",
        "    \"\"\"\n",
        "    # 1. Handle missing values\n",
        "    df = process_missing_value(df)\n",
        "\n",
        "    # 2. Handle outliers\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    ratio_cols = ['debtToTotalAssets', 'niToAsset', 'ROA', 'EPS_', 'revenueGrowth', 'netIncomeGrowth', 'currentRatio', \n",
        "                  'm2m1GrowthGap', 'm2Velocity', 'primeRate'\n",
        "                  ]  # Exclude ratio columns\n",
        "    cols_to_process = list(set(numeric_cols) - set(ratio_cols))\n",
        "    df = handle_outliers(df, cols_to_process)\n",
        "\n",
        "    df = encode_categorical_features(df, ['ticker', 'companyName'])\n",
        "# capitalExpenditure_ totalAssets_\n",
        "# commonSharesOutstanding_\n",
        "    log_transform_cols = [\n",
        "    \"commonSharesTraded_\",  # Max 1.13B, mean 21.8M (highly skewed)\n",
        "    \"salePrice\",            # Large monetary values\n",
        "    # \"totalAssets_\",         # Max 122,520, mean 2,366 (right-skewed)\n",
        "    \"capitalExpenditure_\",  # Max visible in stats, likely right-skewed\n",
        "    \"m2SA\",                # Large monetary aggregate values\n",
        "    \"shareholdersEquity_\"  # Max 46,740, mean 782 (highly skewed)\n",
        "\n",
        "    ]\n",
        "    df = apply_log_transform(df, log_transform_cols)\n",
        "\n",
        "    #  Add time series features\n",
        "    df = add_time_series_features(df)\n",
        "\n",
        "    # 5. Scale features\n",
        "    scale_columns = [\n",
        "        \"commonSharesOutstanding_\",\n",
        "        \"netIncome_\",\n",
        "        \"operatingIncome_\",\n",
        "        \"costOfGoodsSold_\",\n",
        "        \"realGDPSA\"\n",
        "    ]\n",
        "\n",
        "    # ['debtToTotalAssets', 'niToAsset', 'ROA', 'currentRatio',\n",
        "    #  'revenueGrowth', 'netIncomeGrowth', 'ebitdaGrowth',\n",
        "    #  'ebitdaMargin', 'realGDPSA', 'm2SA']\n",
        "\n",
        "    df = scale_features(df, scale_columns)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Execute preprocessing\n",
        "processed_df = preprocess_numeric_data(selected_companies.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b41bda",
      "metadata": {
        "id": "b8b41bda"
      },
      "source": [
        "# Preprocessing Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17a59f39",
      "metadata": {
        "id": "17a59f39"
      },
      "source": [
        "## Verify outliers detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bb8349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "f1bb8349",
        "outputId": "41b782ad-c4dc-4bcb-f271-b12e92956c11"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_outliers(df_before, df_after, column):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.boxplot(df_before[column].dropna())\n",
        "    plt.title(f\"Before Outlier Handling: {column}\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.boxplot(df_after[column].dropna())\n",
        "    plt.title(f\"After Outlier Handling: {column}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "compare_outliers(selected_companies, processed_df, 'capitalExpenditure_')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c35eefc",
      "metadata": {
        "id": "1c35eefc"
      },
      "source": [
        "## Verify scaling performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8827cf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "d8827cf1",
        "outputId": "7042fef8-06ff-46f5-c763-1655ae8bddd8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "def check_scaling(df_before, df_after, column):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df_before[column], kde=True)\n",
        "    plt.title(f\"Before Scaling: {column}\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(df_after[column], kde=True)\n",
        "    plt.title(f\"After Scaling: {column}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# ç¤ºä¾‹ï¼šæ£€æŸ¥totalAssets_çš„ç¼©æ”¾æ•ˆæžœ\n",
        "check_scaling(selected_companies, processed_df, 'totalAssets_')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e549c74",
      "metadata": {
        "id": "2e549c74"
      },
      "source": [
        "## Check numerical features distribution after preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150f8d91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "150f8d91",
        "outputId": "dcea5cc0-321f-4dc5-e384-e8683f6e9ed8"
      },
      "outputs": [],
      "source": [
        "def plot_distribution_comparison(df_before, df_after, columns, log_scale=False):\n",
        "    for col in columns:\n",
        "        plt.figure(figsize=(10, 4))\n",
        "\n",
        "        # Distribution before processing\n",
        "        plt.subplot(1, 2, 1)\n",
        "        sns.histplot(df_before[col], kde=True, color='blue')\n",
        "        if log_scale:\n",
        "            plt.yscale('log')\n",
        "        plt.title(f\"Before: {col}\")\n",
        "\n",
        "        # Distribution after processing\n",
        "        plt.subplot(1, 2, 2)\n",
        "        sns.histplot(df_after[col], kde=True, color='green')\n",
        "        if log_scale:\n",
        "            plt.yscale('log')\n",
        "        plt.title(f\"After: {col}\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Example: Check key numerical columns\n",
        "numeric_cols = ['operatingIncome_', 'totalAssets_']\n",
        "plot_distribution_comparison(selected_companies, processed_df, numeric_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022564a6",
      "metadata": {
        "id": "022564a6"
      },
      "source": [
        "## Check correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f92847",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "c6f92847",
        "outputId": "496a562b-42ef-44dd-f8ca-e22a81c3bf24"
      },
      "outputs": [],
      "source": [
        "def compare_correlation(df_before, df_after):\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # Drop the 'EBITDA' column before calculating correlations\n",
        "    df_before_corr = df_before.drop(columns=['EBITDA']).select_dtypes(include=['float64']).corr()\n",
        "    df_after_corr = df_after.drop(columns=['EBITDA']).select_dtypes(include=['float64']).corr()\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.heatmap(df_before_corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title(\"Before Preprocessing\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.heatmap(df_after_corr, annot=False, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    plt.title(\"After Preprocessing\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "compare_correlation(selected_companies, processed_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b40ad03d",
      "metadata": {
        "id": "b40ad03d"
      },
      "source": [
        "# Save files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f2e125",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75f2e125",
        "outputId": "e47801f8-6234-4b5f-f23e-09ea36f622d8"
      },
      "outputs": [],
      "source": [
        "processed_df.to_csv(\"revenue_new.csv\", index=False)\n",
        "print(\"New CSV file created: revenue_new.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b8a482",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98b8a482",
        "outputId": "65f0dc89-3564-426a-a1db-d4ebdf7cfd79"
      },
      "outputs": [],
      "source": [
        "# æ‰“å°æ¯ä¸€åˆ—çš„æ•°æ®ç»Ÿè®¡\n",
        "print(df.describe(include='all'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387137c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "387137c1",
        "outputId": "e2b6a236-2fbb-401e-9083-ae224ce29e83"
      },
      "outputs": [],
      "source": [
        "# æ‰“å° EBITDA åˆ—çš„ç»Ÿè®¡ä¿¡æ¯\n",
        "print(df['EBITDA'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee6976f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ee6976f5",
        "outputId": "00b24096-deb4-402c-d4ad-fd1385ae8081"
      },
      "outputs": [],
      "source": [
        "# æ‰“å°EBITDAçš„æ•°å€¼åˆ†å¸ƒ\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['EBITDA'], bins=30, kde=True)\n",
        "plt.title('EBITDA Distribution')\n",
        "plt.xlabel('EBITDA')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0cfa1e7",
      "metadata": {
        "id": "b0cfa1e7"
      },
      "source": [
        "done\n",
        "<!--\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡\n",
        "features = ['capitalExpenditure_', 'netIncome_', 'operatingIncome_', 'shareholdersEquity_',\n",
        "            'totalAssets_', 'EPS_', 'debtToTotalAssets', 'niToAsset', 'ROA', 'revenueGrowth',\n",
        "            'quickRatio', 'rsi', 'mva', 'cfroi', 'salePrice', 'realGDPSA', 'm2SA',\n",
        "            'm2MinusM1SA', 'm2Velocity', 'primeRate', 'EBITDA_lag1']\n",
        "target = 'EBITDA'\n",
        "\n",
        "# åŽ»é™¤ç¼ºå¤±å€¼\n",
        "processed_df = processed_df.dropna(subset=features + [target])\n",
        "\n",
        "# æ•°æ®å½’ä¸€åŒ–\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(processed_df[features + [target]])\n",
        "\n",
        "# æž„é€ æ—¶é—´åºåˆ—æ•°æ®\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i+seq_length, :-1])\n",
        "        y.append(data[i+seq_length, -1])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 10  # æ—¶é—´æ­¥é•¿\n",
        "X, y = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# æž„å»ºLSTMæ¨¡åž‹\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# ç¼–è¯‘æ¨¡åž‹\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# è®­ç»ƒæ¨¡åž‹\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# é¢„æµ‹\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# åå½’ä¸€åŒ–é¢„æµ‹å€¼å’ŒçœŸå®žå€¼\n",
        "y_test_rescaled = scaler.inverse_transform(np.hstack((np.zeros((y_test.shape[0], len(features))), y_test.reshape(-1, 1))))[:, -1]\n",
        "y_pred_rescaled = scaler.inverse_transform(np.hstack((np.zeros((y_pred.shape[0], len(features))), y_pred)))[:, -1]\n",
        "\n",
        "# è¯„ä¼°æ¨¡åž‹æ€§èƒ½\n",
        "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R^2 Score: {r2}\") -->"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
